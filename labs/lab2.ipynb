{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#Задание 1.\n",
    "Реализуйте полносвязную нейронную сеть с помощью библиотеки Tensor Flow. В качестве алгоритма оптимизации можно использовать, например, стохастический градиент (Stochastic Gradient Descent, SGD). Определите количество скрытых слоев от 1 до 5, количество нейронов в каждом из слоев до нескольких сотен, а также их функции активации (кусочно-линейная, сигмоидная, гиперболический тангенс и т.д.)."
   ],
   "id": "63b0026650f0e5ce",
   "attachments": {
    "cc24f2aa-71ba-4db7-b36c-744821075bd9.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5kAAADLCAIAAABrmsAQAAACNklEQVR4Xu3BAQ0AAADCoPdPbQ8HFAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHwYkDwAAR4wnQEAAAAASUVORK5CYII="
    }
   }
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-26T17:41:19.251397Z",
     "start_time": "2025-10-26T17:32:19.236334Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Параметры\n",
    "dataset_path = \"notMNIST_large\"\n",
    "image_size = (28, 28)\n",
    "hidden_layers = [256, 128, 64]  # ← можно задать от 1 до 5 слоёв, до нескольких сотен нейронов\n",
    "X, y = [], []\n",
    "classes = sorted(os.listdir(dataset_path))\n",
    "\n",
    "# Загрузка изображений\n",
    "for label, class_name in enumerate(classes):\n",
    "    class_folder = os.path.join(dataset_path, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "        for fname in os.listdir(class_folder):\n",
    "            if fname.endswith('.png'):\n",
    "                try:\n",
    "                    img_path = os.path.join(class_folder, fname)\n",
    "                    img = Image.open(img_path).convert('L').resize(image_size)\n",
    "                    X.append(np.array(img).flatten() / 255.0)\n",
    "                    y.append(label)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Построение модели\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(28 * 28,)))\n",
    "\n",
    "for units in hidden_layers:\n",
    "    model.add(tf.keras.layers.Dense(units, activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Обучение\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Оценка\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Точность на тестовой выборке: {test_acc:.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m11906/11906\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m34s\u001B[0m 2ms/step - accuracy: 0.8413 - loss: 0.5475 - val_accuracy: 0.8672 - val_loss: 0.4510\n",
      "Epoch 2/10\n",
      "\u001B[1m11906/11906\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 2ms/step - accuracy: 0.8756 - loss: 0.4156 - val_accuracy: 0.8829 - val_loss: 0.3975\n",
      "Epoch 3/10\n",
      "\u001B[1m11906/11906\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m37s\u001B[0m 3ms/step - accuracy: 0.8889 - loss: 0.3705 - val_accuracy: 0.8898 - val_loss: 0.3700\n",
      "Epoch 4/10\n",
      "\u001B[1m11906/11906\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 2ms/step - accuracy: 0.8975 - loss: 0.3414 - val_accuracy: 0.8916 - val_loss: 0.3608\n",
      "Epoch 5/10\n",
      "\u001B[1m11906/11906\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 2ms/step - accuracy: 0.9033 - loss: 0.3203 - val_accuracy: 0.8990 - val_loss: 0.3381\n",
      "Epoch 6/10\n",
      "\u001B[1m11906/11906\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 2ms/step - accuracy: 0.9079 - loss: 0.3036 - val_accuracy: 0.9024 - val_loss: 0.3286\n",
      "Epoch 7/10\n",
      "\u001B[1m11906/11906\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 1ms/step - accuracy: 0.9119 - loss: 0.2894 - val_accuracy: 0.9044 - val_loss: 0.3233\n",
      "Epoch 8/10\n",
      "\u001B[1m11906/11906\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 2ms/step - accuracy: 0.9153 - loss: 0.2776 - val_accuracy: 0.9049 - val_loss: 0.3187\n",
      "Epoch 9/10\n",
      "\u001B[1m11906/11906\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 2ms/step - accuracy: 0.9182 - loss: 0.2671 - val_accuracy: 0.8389 - val_loss: 0.5594\n",
      "Epoch 10/10\n",
      "\u001B[1m11906/11906\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 2ms/step - accuracy: 0.9207 - loss: 0.2577 - val_accuracy: 0.9042 - val_loss: 0.3185\n",
      "\u001B[1m3307/3307\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 1ms/step - accuracy: 0.9044 - loss: 0.3197\n",
      "Точность на тестовой выборке: 0.9044\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#Задание 2.\n",
    "#Как улучшилась точность классификатора по сравнению с логистической регрессией?\n",
    "#Точность улучшилась на 1%"
   ],
   "id": "cf60253f7d3e60cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#Задание 3.\n",
    "#Используйте регуляризацию и метод сброса нейронов (dropout) для борьбы с переобучением. Как улучшилось качество классификации?"
   ],
   "id": "f518d6f344876063",
   "attachments": {
    "e69172b5-f1ca-4acf-8f91-9619f1133d94.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5kAAAB1CAIAAABLWrIVAAABUElEQVR4Xu3BMQEAAADCoPVPbQsvoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB4G+94AAFFwNa/AAAAAElFTkSuQmCC"
    }
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T17:23:48.021434Z",
     "start_time": "2025-10-26T17:23:40.220298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "\n",
    "# Пример архитектуры с регуляризацией и Dropout\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(28 * 28,)),\n",
    "\n",
    "    # Первый скрытый слой с L2-регуляризацией и Dropout\n",
    "    layers.Dense(256, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    # Второй скрытый слой\n",
    "    layers.Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    # Выходной слой\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Обучение\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Оценка\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Точность на тестовой выборке: {test_acc:.4f}\")"
   ],
   "id": "5ada3d1ca3718ab7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.5095 - loss: 2.0835 - val_accuracy: 0.8344 - val_loss: 1.3314\n",
      "Epoch 2/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.7656 - loss: 1.3711 - val_accuracy: 0.8598 - val_loss: 1.1193\n",
      "Epoch 3/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8125 - loss: 1.2085 - val_accuracy: 0.8778 - val_loss: 1.0363\n",
      "Epoch 4/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8391 - loss: 1.1238 - val_accuracy: 0.8792 - val_loss: 1.0013\n",
      "Epoch 5/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8516 - loss: 1.0763 - val_accuracy: 0.8825 - val_loss: 0.9762\n",
      "Epoch 6/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8593 - loss: 1.0431 - val_accuracy: 0.8879 - val_loss: 0.9575\n",
      "Epoch 7/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8642 - loss: 1.0187 - val_accuracy: 0.8912 - val_loss: 0.9426\n",
      "Epoch 8/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8705 - loss: 0.9893 - val_accuracy: 0.8912 - val_loss: 0.9309\n",
      "Epoch 9/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8733 - loss: 0.9748 - val_accuracy: 0.8959 - val_loss: 0.9184\n",
      "Epoch 10/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8794 - loss: 0.9571 - val_accuracy: 0.8919 - val_loss: 0.9076\n",
      "Epoch 11/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8832 - loss: 0.9376 - val_accuracy: 0.8945 - val_loss: 0.8995\n",
      "Epoch 12/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8853 - loss: 0.9215 - val_accuracy: 0.8965 - val_loss: 0.8916\n",
      "Epoch 13/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8858 - loss: 0.9159 - val_accuracy: 0.8965 - val_loss: 0.8837\n",
      "Epoch 14/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8843 - loss: 0.9081 - val_accuracy: 0.8972 - val_loss: 0.8756\n",
      "Epoch 15/15\n",
      "\u001B[1m211/211\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8885 - loss: 0.8933 - val_accuracy: 0.8985 - val_loss: 0.8676\n",
      "\u001B[1m118/118\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8999 - loss: 0.8501  \n",
      "Точность на тестовой выборке: 0.8999\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#Задание 4.\n",
    "#Воспользуйтесь динамически изменяемой скоростью обучения (learning rate). Наилучшая точность, достигнутая с помощью данной модели составляет 97.1%. Какую точность демонстрирует Ваша реализованная модель?\n",
    "94.53%"
   ],
   "id": "c1451f7876a789c0",
   "attachments": {
    "9367b842-ae50-4caf-bbe4-033d8f828569.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7oAAACSCAIAAADkcSH8AAABrElEQVR4Xu3BgQAAAADDoPlTX+EAVQEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADwGYSgAAegrTHQAAAAASUVORK5CYII="
    }
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T17:50:50.724382Z",
     "start_time": "2025-10-26T17:48:15.274005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Функция изменения learning rate по эпохам\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 10:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Обучение с динамическим learning rate\n",
    "model.fit(X_train, y_train, epochs=15, batch_size=64,\n",
    "          validation_split=0.1, callbacks=[lr_callback])\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Точность на тестовой выборке: {test_acc:.4f}\")\n"
   ],
   "id": "2bf1c32452b15f84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 2ms/step - accuracy: 0.9278 - loss: 0.2363 - val_accuracy: 0.9090 - val_loss: 0.3095 - learning_rate: 0.0100\n",
      "Epoch 2/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 2ms/step - accuracy: 0.9296 - loss: 0.2302 - val_accuracy: 0.9104 - val_loss: 0.3065 - learning_rate: 0.0100\n",
      "Epoch 3/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 2ms/step - accuracy: 0.9311 - loss: 0.2253 - val_accuracy: 0.9103 - val_loss: 0.3101 - learning_rate: 0.0100\n",
      "Epoch 4/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9326 - loss: 0.2206 - val_accuracy: 0.9109 - val_loss: 0.3095 - learning_rate: 0.0100\n",
      "Epoch 5/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9337 - loss: 0.2163 - val_accuracy: 0.9120 - val_loss: 0.3056 - learning_rate: 0.0100\n",
      "Epoch 6/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9381 - loss: 0.2040 - val_accuracy: 0.9126 - val_loss: 0.3035 - learning_rate: 0.0050\n",
      "Epoch 7/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9390 - loss: 0.2012 - val_accuracy: 0.9129 - val_loss: 0.3034 - learning_rate: 0.0050\n",
      "Epoch 8/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9395 - loss: 0.1988 - val_accuracy: 0.9124 - val_loss: 0.3060 - learning_rate: 0.0050\n",
      "Epoch 9/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9402 - loss: 0.1963 - val_accuracy: 0.9130 - val_loss: 0.3028 - learning_rate: 0.0050\n",
      "Epoch 10/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9412 - loss: 0.1939 - val_accuracy: 0.9134 - val_loss: 0.3072 - learning_rate: 0.0050\n",
      "Epoch 11/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9444 - loss: 0.1849 - val_accuracy: 0.9139 - val_loss: 0.3042 - learning_rate: 0.0010\n",
      "Epoch 12/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9449 - loss: 0.1838 - val_accuracy: 0.9136 - val_loss: 0.3047 - learning_rate: 0.0010\n",
      "Epoch 13/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9451 - loss: 0.1831 - val_accuracy: 0.9141 - val_loss: 0.3049 - learning_rate: 0.0010\n",
      "Epoch 14/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9451 - loss: 0.1826 - val_accuracy: 0.9139 - val_loss: 0.3054 - learning_rate: 0.0010\n",
      "Epoch 15/15\n",
      "\u001B[1m5953/5953\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 2ms/step - accuracy: 0.9453 - loss: 0.1820 - val_accuracy: 0.9137 - val_loss: 0.3051 - learning_rate: 0.0010\n",
      "\u001B[1m3307/3307\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 1ms/step - accuracy: 0.9135 - loss: 0.3070\n",
      "Точность на тестовой выборке: 0.9135\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
