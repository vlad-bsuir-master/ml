{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Реализуйте нейронную сеть с двумя сверточными слоями, и одним полносвязным с нейронами с кусочно-линейной функцией активации.",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "очистка от битых картинок",
   "id": "eb346cf744aff8d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T17:32:40.449097Z",
     "start_time": "2025-12-07T17:23:53.748864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "def clean_notmnist(src_root: str, dst_root: str):\n",
    "    os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "    classes = sorted(os.listdir(src_root))\n",
    "    for cls in classes:\n",
    "        src_dir = os.path.join(src_root, cls)\n",
    "        dst_dir = os.path.join(dst_root, cls)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "        for fname in os.listdir(src_dir):\n",
    "            src_path = os.path.join(src_dir, fname)\n",
    "            dst_path = os.path.join(dst_dir, fname)\n",
    "            try:\n",
    "                # Проверяем, что файл действительно открывается как изображение\n",
    "                with Image.open(src_path) as img:\n",
    "                    img.verify()\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "            except (UnidentifiedImageError, OSError):\n",
    "                print(\"Skipping corrupted:\", src_path)\n",
    "\n",
    "# Использование:\n",
    "# укажи путь к исходному датасету и папку для чистого\n",
    "clean_notmnist(\"notMNIST_large\", \"notMNIST_clean\")"
   ],
   "id": "ea25cda54cffcf80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping corrupted: notMNIST_large\\A\\RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png\n",
      "Skipping corrupted: notMNIST_large\\A\\SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png\n",
      "Skipping corrupted: notMNIST_large\\A\\Um9tYW5hIEJvbGQucGZi.png\n",
      "Skipping corrupted: notMNIST_large\\B\\TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png\n",
      "Skipping corrupted: notMNIST_large\\D\\VHJhbnNpdCBCb2xkLnR0Zg==.png\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T17:36:33.317847Z",
     "start_time": "2025-12-07T17:36:19.078763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "def clean_notmnist(src_root: str, dst_root: str):\n",
    "    os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "    classes = sorted(os.listdir(src_root))\n",
    "    for cls in classes:\n",
    "        src_dir = os.path.join(src_root, cls)\n",
    "        dst_dir = os.path.join(dst_root, cls)\n",
    "        os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "        for fname in os.listdir(src_dir):\n",
    "            src_path = os.path.join(src_dir, fname)\n",
    "            dst_path = os.path.join(dst_dir, fname)\n",
    "            try:\n",
    "                # Проверяем, что файл действительно открывается как изображение\n",
    "                with Image.open(src_path) as img:\n",
    "                    img.verify()\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "            except (UnidentifiedImageError, OSError):\n",
    "                print(\"Skipping corrupted:\", src_path)\n",
    "\n",
    "# Использование:\n",
    "# укажи путь к исходному датасету и папку для чистого\n",
    "clean_notmnist(\"notMNIST_small\", \"notMNIST_clean_small\")"
   ],
   "id": "80428b3a42497444",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping corrupted: notMNIST_small\\A\\RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png\n",
      "Skipping corrupted: notMNIST_small\\F\\Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T18:36:47.310598Z",
     "start_time": "2025-12-07T17:40:11.517506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# Трансформации: тензоризация + нормализация\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# Загрузка датасета (структура папок: train/A, train/B, ..., test/A, ...)\n",
    "train_dataset = datasets.ImageFolder(root=\"notMNIST_clean\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=\"notMNIST_clean_small\", transform=transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Кусочно-линейная активация (пример: LeakyReLU)\n",
    "class PLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.where(x >= 0, x, 0.1 * x)\n",
    "\n",
    "# Модель: 2 Conv + 1 FC\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 10)  # 10 классов\n",
    "        self.plu = PLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.plu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(self.plu(self.conv2(x)), 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Цикл обучения\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, loss={loss.item():.4f}\")\n",
    "\n",
    "# Оценка\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == target).sum().item()\n",
    "        total += target.size(0)\n",
    "\n",
    "print(f\"Test accuracy: {correct/total:.4f}\")\n"
   ],
   "id": "29cd7558db7e8cd5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=0.7934\n",
      "Epoch 2, loss=0.7177\n",
      "Epoch 3, loss=0.1342\n",
      "Epoch 4, loss=0.2368\n",
      "Epoch 5, loss=0.4906\n",
      "Test accuracy: 0.9607\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Какова точность построенной модели?",
   "id": "763d050ae08e597e",
   "attachments": {
    "0261e5c2-8cd0-4501-9d0d-dbc95aa7c144.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5kAAAAsCAIAAABg2+sqAAAAjUlEQVR4Xu3BMQEAAADCoPVPbQo/oAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIC3AdsfAAGwP8xBAAAAAElFTkSuQmCC"
    }
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Замените сверточные слои на слои, реализующие операцию пулинга (Pooling) с функцией максимума или среднего. Как это повлияло на точность классификатора?",
   "id": "9a8744c8ab510a84",
   "attachments": {
    "c5ee4395-b40f-4ad8-986e-44dc4f694192.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA5kAAABJCAIAAAA44nXDAAAA2klEQVR4Xu3BMQEAAADCoPVP7W0HoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOANFFkAARGRX1gAAAAASUVORK5CYII="
    }
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T19:48:35.788812Z",
     "start_time": "2025-12-07T19:21:26.421715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ---------- Кастомный Dataset, который пропускает битые изображения ----------\n",
    "class NotMNISTDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        classes = sorted(os.listdir(root))\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(classes)}\n",
    "        for cls in classes:\n",
    "            cls_dir = os.path.join(root, cls)\n",
    "            for fname in os.listdir(cls_dir):\n",
    "                path = os.path.join(cls_dir, fname)\n",
    "                try:\n",
    "                    with Image.open(path) as img:\n",
    "                        img.verify()  # проверка\n",
    "                    self.samples.append((path, self.class_to_idx[cls]))\n",
    "                except Exception:\n",
    "                    # просто пропускаем битые файлы\n",
    "                    pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, target = self.samples[idx]\n",
    "        img = Image.open(path).convert(\"L\")  # grayscale\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "# ---------- Кусочно-линейная активация ----------\n",
    "class PLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.where(x >= 0, x, 0.1 * x)\n",
    "\n",
    "# ---------- Модель с Pooling ----------\n",
    "class PoolingNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(PoolingNet, self).__init__()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(7 * 7, num_classes)\n",
    "        self.plu = PLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(x)   # 28x28 → 14x14\n",
    "        x = self.pool2(x)   # 14x14 → 7x7\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return self.plu(x)\n",
    "\n",
    "# ---------- Основной скрипт ----------\n",
    "def main():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    train_dataset = NotMNISTDataset(root=\"notMNIST_clean\", transform=transform)\n",
    "    test_dataset = NotMNISTDataset(root=\"notMNIST_clean_small\", transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "    model = PoolingNet(num_classes=10)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Обучение\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, loss={loss.item():.4f}\")\n",
    "\n",
    "    # Тест\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "    print(f\"Test accuracy: {correct/total:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "87db5e9f87823ef3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=0.2611\n",
      "Epoch 2, loss=0.5520\n",
      "Epoch 3, loss=0.6099\n",
      "Epoch 4, loss=0.7484\n",
      "Epoch 5, loss=0.8015\n",
      "Test accuracy: 0.8908\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a36320b3813d0302"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
